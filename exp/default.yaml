# Path of byte-pair encoding model file.
bpe: bpe.37000.model

model:
# hidden_size: Number of hidden units in GRU cells.
# drop_p: Dropout rate.
# use_bn: Whether to insert BatchNorm in EncoderRNN.
# encoder_layers: EncoderRNN layers.
# decoder_layers: DecoderRNN layers.
    hidden_size: 512
    drop_p: 0.2
    use_bn: true
    encoder_layers: 2
    decoder_layers: 2

train:
# batch_size: Batch size.
# init_lr: Initial learning rate. Note the solver we use is Adam.
# metric: Quantity the learning rate scheduler will monitore. One of 'loss' or 'bleu'.
# decay_factor: Learning rate decay factor.
# patience: Number of epochs with no improvement after which learning rate will be reduced.
    batch_size: 64
    init_lr: 0.0003
    metric: bleu
    decay_factor : 0.5
    patience: 1
